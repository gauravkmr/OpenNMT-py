Server: tesla
Raw Data Location:
    /data1/gauku/lowresource_mt/<LANG_CODE>/raw

Train, Valid, and Test Data Location:
    /data1/gauku/lowresource_mt/<LANG_CODE>/data

Preprocessed Data Location:
    /data1/gauku/lowresource_mt/<LANG_CODE>/data

Trained models:
    /data1/gauku/lowresource_mt/<LANG_CODE>/models



The below steps to get and preprocess Hindi-English data. Process is same for other languages.

STEPS:

#Getting data
1.  Login to tesla
2.  cd to the directory where you want to fetch files from ELISA server
3.  Login to ELISA sftp server
4.  Navigate to directory where file is located
5.  Copy the required files
    eg. to copy hin-eng files, run 'get elisa.hin*'


#Unzip the data files
cd /data1/gauku/lowresource_mt/hin/raw
tar xfz *.nomono.tgz
cd *.nomono
gunzip *.xml.gz

#Unzip monolingual data file
cd /data1/gauku/lowresource_mt/hin/raw
g


#Create conda env
conda create --name my_env python=3.6


#Extracting sentence pairs
1.  Clone OpenNMT-py, if not already done so
    git clone https://github.com/gauravkmr/OpenNMT-py.git
2.  cd OpenNMT-py
3.  git checkout bilingual
4.  source activate my_env
5.  pip install -r requirements.txt
6.  cd /scripts
7.  Run the below command to generate source target pairs
    #train
    python extract_data.py -lang hin -prefix train \
        -in /data1/gauku/lowresource_mt/hin/raw/elisa.hin.package.y3r1.v2.nomono/elisa.hin-eng.train.y3r1.v2.xml \
        -tags "LRLP_TOKENIZED" \
        -out /data1/gauku/lowresource_mt/hin/data/

    #test
    python extract_data.py -lang hin -prefix test \
        -in /data1/gauku/lowresource_mt/hin/raw/elisa.hin.package.y3r1.v2.nomono/elisa.hin-eng.test.y3r1.v2.xml \
        -tags "LRLP_TOKENIZED" \
        -out /data1/gauku/lowresource_mt/hin/data/

    #dev
    python extract_data.py -lang hin -prefix dev \
        -in /data1/gauku/lowresource_mt/hin/raw/elisa.hin.package.y3r1.v2.nomono/elisa.hin-eng.dev.y3r1.v2.xml \
        -tags "LRLP_TOKENIZED" \
        -out /data1/gauku/lowresource_mt/hin/data/


#Extracting monolingual data
cd OpenNMT-py/scripts
python extract_monolingual_data.py -lang hin \
        -in /data1/gauku/lowresource_mt/hin/raw/elisa.hin.y3r1.v2.xml \
        -tags "LRLP_TOKENIZED" \
        -out /data1/gauku/lowresource_mt/hin/data/


#Preprocess
python preprocess.py -train_src /data1/gauku/lowresource_mt/hin/data/hin_train_LRLP_TOKENIZED_SOURCE.txt \
                     -train_tgt /data1/gauku/lowresource_mt/hin/data/hin_train_LRLP_TOKENIZED_TARGET.txt \
                     -valid_src /data1/gauku/lowresource_mt/hin/data/hin_dev_LRLP_TOKENIZED_SOURCE.txt \
                     -valid_tgt /data1/gauku/lowresource_mt/hin/data/hin_dev_LRLP_TOKENIZED_TARGET.txt \
                     -save_data /data1/gauku/lowresource_mt/hin/data/hin \
                     -src_seq_length 150 \
                     -tgt_seq_length 150

Note:
-save_data: last part ('hin' in this case) is used as filename prefix


Generated files:
/data1/gauku/lowresource_mt/hin/data/
        - hin.train.0.pt
        - hin.valid.0.pt
        - hin.vocab.pt


#GENERATE EMBEDDINGS - fasttext
cd OpenNMT-py
cp tools/embeddings_to_torch.py .
python embeddings_to_torch.py -emb_file_enc "/data1/reno/low_resource_mt/embeddings/wiki.hi.vec" \
                                    -emb_file_dec "/data1/reno/low_resource_mt/embeddings/wiki.en.vec" \
                                    -dict_file "/data1/gauku/lowresource_mt/hin/data/hin.vocab.pt" \
                                    -output_file "/data1/gauku/lowresource_mt/hin/data/fasttext_embeddings"


#GENERATE EMBEDDINGS - muse
python embeddings_to_torch.py -emb_file_enc "/data1/reno/low_resource_mt/embeddings/bilingual-hi.txt" \
                                    -emb_file_dec "/data1/reno/low_resource_mt/embeddings/bilingual-en.txt" \
                                    -dict_file "/data1/gauku/lowresource_mt/hin/data/hin.vocab.pt" \
                                    -output_file "/data1/gauku/lowresource_mt/hin/data/muse_embeddings"


#Training
1.  BASELINE RNN MODEL
    python train.py -config config/config-rnn-base.yml

    OR

    python train.py -data /data1/gauku/lowresource_mt/hin/data/hin \
                -save_model /data1/gauku/lowresource_mt/hin/models/hin_without_embeddings_baseline/hin_without_embedding \
                -world_size 2 \
                -gpu_ranks 0 1

    Usage:
    -data: location of files generated by preprocess.py with the filename prefix ('hin' in this case)
    -save_model: location where you want to save the generted model. The last part (after last '/') serves as model name prefix


2.  BASELINE TRANSFORMER MODEL
    python train.py -config config/config-transformer-base.yml


3.  FASTTEXT
    python train.py -config config/config-transformer-fasttext-embeddings.yml


4.  MUSE
    python train.py -config config/config-transformer-muse-embeddings.yml



#Translate
python translate.py -model /data1/gauku/lowresource_mt/hin/models/hin_without_embeddings_baseline/hin_without_embedding_step_100000.pt \
                    -src /data1/gauku/lowresource_mt/hin/data/hin_test_LRLP_TOKENIZED_SOURCE.txt \
                    -output /data1/gauku/lowresource_mt/hin/data/hin_test_LRLP_TOKENIZED_MODELPRED.txt \
                    -replace_unk -verbose



python translate.py -model /data1/gauku/lowresource_mt/hin/models/hin_without_embeddings_baseline/hin_without_embedding_step_100000.pt \
                    -src /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.hi \
                    -output /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.en.hin_without_embedding_step_100000.pt \
                    -replace_unk -verbose


python translate.py -model /data1/gauku/lowresource_mt/hin/models/hin_without_embeddings_transformer/hin_noembed_transformer_step_5550.pt \
                    -src /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.hi \
                    -output /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.en.hin_noembed_transformer_step_5550.pt \
                    -replace_unk -verbose

python translate.py -model /data1/gauku/lowresource_mt/hin/models/hin_fasttext_embeddings_transformer/hin_fasttext_transformer_step_5000.pt \
                    -src /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.hi \
                    -output /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.en.hin_fasttext_transformer_step_5000.pt \
                    -replace_unk -verbose

python translate.py -model /data1/gauku/lowresource_mt/hin/models/hin_muse_embeddings_transformer/hin_muse_transformer_step_5000.pt \
                    -src /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.hi \
                    -output /data1/gauku/lowresource_mt/hin/data/external/dev_test/test.en.hin_muse_transformer_step_5000.pt \
                    -replace_unk -verbose